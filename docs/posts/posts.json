[
  {
    "path": "posts/2021-01-29-day-6-stringr/",
    "title": "Day 6 - stringr::str_trim()",
    "description": "The 6th most used R package is... stringr!",
    "author": [],
    "date": "2021-01-27",
    "categories": [],
    "contents": "\r\nstringr\r\nThe stringr package is all about the manipulation of strings in R (pretty self explanatory right?). It’s inclusion in the tidyverse collective means, in my mind, it is one of the most useful packages for R out there. I haven’t used stringr much, but I am familiar with regex or regular expressions using python to search for and replace specific patterns of strings. By the looks of it, stringr makes the syntax for string detection and manipulation a little easier in R and it works out of the box with %>% function chains. The regex functionality for more advanced string manipulations is also available using stringr.\r\nFor more stringr introductions: stringr vignette\r\n\r\n\r\nTable 1: Top 10 stringr Functions\r\n\r\n\r\nContent\r\n\r\n\r\nCount\r\n\r\n\r\nstr_detect\r\n\r\n\r\n2457\r\n\r\n\r\nstr_replace_all\r\n\r\n\r\n2322\r\n\r\n\r\nstr_replace\r\n\r\n\r\n1465\r\n\r\n\r\nstr_c\r\n\r\n\r\n1171\r\n\r\n\r\nstr_trim\r\n\r\n\r\n1128\r\n\r\n\r\nstr_sub\r\n\r\n\r\n965\r\n\r\n\r\nstr_split\r\n\r\n\r\n929\r\n\r\n\r\nstr_extract\r\n\r\n\r\n902\r\n\r\n\r\nstr_split_fixed\r\n\r\n\r\n667\r\n\r\n\r\nstr_match\r\n\r\n\r\n387\r\n\r\n\r\nstringr::str_trim()\r\nMore often then not, a split string or a hand-me-down data set will include some strings with strange and difficult to visually detect white space such as accidental tab spaces, extra spaces, and return lines. str_trim() helps remove all leading and trailing white space from strings. The function itself is easy to remember and always useful. Similarly, str_squish() removes excess white space.\r\nExample\r\n\r\n\r\nstr_trim(\"  String with trailing and leading white space\\t\")\r\n\r\n\r\n[1] \"String with trailing and leading white space\"\r\n\r\nstr_trim(\"\\n\\nString with trailing and leading white space\\n\\n\")\r\n\r\n\r\n[1] \"String with trailing and leading white space\"\r\n\r\nstr_squish(\"  String with trailing,  middle, and leading white space\\t\")\r\n\r\n\r\n[1] \"String with trailing, middle, and leading white space\"\r\n\r\nstr_squish(\"\\n\\nString with excess,  trailing and leading white   space\\n\\n\")\r\n\r\n\r\n[1] \"String with excess, trailing and leading white space\"\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-01-29T16:21:17-08:00",
    "input_file": "day-6-stringr.utf8.md"
  },
  {
    "path": "posts/2021-01-27-day-5-reshape2/",
    "title": "Day 5 - reshape2::melt()",
    "description": "The 5th most used R package is... reshape2?!",
    "author": [],
    "date": "2021-01-26",
    "categories": [],
    "contents": "\r\nReshape2\r\nFrustrated with wide format data when it needs to be long for plotting or aggregating? Or long data when you want it to be wide? Look no further than reshape2! Well, perhaps if it was still 2013 and there were no other alternatives. I digress; reshape2 still works and does it well. Would it be the #5 R package used if it didn’t? This package has only 3 functions but the most important one seems to be melt():\r\n\r\n\r\nTable 1: The only 3 reshape2 Functions\r\n\r\n\r\nContent\r\n\r\n\r\nCount\r\n\r\n\r\nmelt\r\n\r\n\r\n5862\r\n\r\n\r\ndcast\r\n\r\n\r\n1514\r\n\r\n\r\nacast\r\n\r\n\r\n202\r\n\r\n\r\nreshape2::melt()\r\nThe melt() function makes data with many columns and fewer rows (wide!), to data with fewer columns and more rows (looooooong).\r\nExample\r\nI am using the base R air quality data set here which has air quality variables in their own columns as well as a month and day column.\r\n\r\n\r\ndata(airquality)\r\nhead(airquality)\r\n\r\n\r\n  Ozone Solar.R Wind Temp Month Day\r\n1    41     190  7.4   67     5   1\r\n2    36     118  8.0   72     5   2\r\n3    12     149 12.6   74     5   3\r\n4    18     313 11.5   62     5   4\r\n5    NA      NA 14.3   56     5   5\r\n6    28      NA 14.9   66     5   6\r\n\r\nBut say we want those air quality variables mapped out into single rows to make our work somewhere else a little less complicated:\r\n\r\n\r\nairquality.long <- reshape2::melt(airquality, id.vars = c(\"Month\", \"Day\")) # makes air quality long and keeps month and day column\r\nhead(distinct(airquality.long, variable, .keep_all = T), 4) # shows each variable in the new long format\r\n\r\n\r\n  Month Day variable value\r\n1     5   1    Ozone  41.0\r\n2     5   1  Solar.R 190.0\r\n3     5   1     Wind   7.4\r\n4     5   1     Temp  67.0\r\n\r\nTo melt() or not to melt()?\r\nMelt was so useful that other people tried to make it better. data.table‘s melt() function claims to work faster and better than reshape2. Tidyverse’s tidyr package also has similar functions called pivot_long() and pivot_wide(). I’m sure these packages’ alternatives will catch up in popularity once they’ve been around as long as reshape2 has!\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-01-29T16:16:23-08:00",
    "input_file": "day-5-reshape2.utf8.md"
  },
  {
    "path": "posts/2021-01-26-day-4-datatable/",
    "title": "Day 4 - data.table::data.table()",
    "description": "The 4th most used R package is... shiny? SKIP... data.table!",
    "author": [],
    "date": "2021-01-25",
    "categories": [],
    "contents": "\r\ndata.table!\r\nIf you are a fan of speed, memory efficiency, and consistent syntax, the data.table package offers some higher level functions that operate well with enterprise-level analyses – I’m talking big data, lots of crunching, where the nanoseconds of every operation count. Sure, most things done in data.table can be done in dplyr and are easier to read that way. But data.table is varsity level R programming. The data.table dialect has a learning curve but the main goal of data.table functions are to keep inherently related processes together (i.e. subsets, joins, aggregations, etc.) As per usual, here are the top 10 most used data.table functions:\r\n\r\n\r\nTable 1: Top 10 data.table Functions on GitHub\r\n\r\n\r\nContent\r\n\r\n\r\nCount\r\n\r\n\r\nset\r\n\r\n\r\n158705\r\n\r\n\r\nsetnames\r\n\r\n\r\n52122\r\n\r\n\r\ndata.table\r\n\r\n\r\n36998\r\n\r\n\r\nsetkey\r\n\r\n\r\n26140\r\n\r\n\r\ncopy\r\n\r\n\r\n17178\r\n\r\n\r\nas.data.table\r\n\r\n\r\n15785\r\n\r\n\r\nmelt\r\n\r\n\r\n14736\r\n\r\n\r\ndcast.data.table\r\n\r\n\r\n13521\r\n\r\n\r\nfread\r\n\r\n\r\n5985\r\n\r\n\r\nrbindlist\r\n\r\n\r\n1733\r\n\r\n\r\ndata.table\r\nThere are only a few functions from the data.table but their primary purpose is to enhance base R data frames. The greatest power comes in manipulating objects with the main function data.table(). There is a good introduction here: Introduction to data.table.\r\nThe main syntax is DT[i, j, by] where i means “on which rows? i.e. WHERE”, j means “what to do i.e SELECT?”, and by means “grouped by what?”.\r\nOr, as mentioned in the help files, “The way to read this out loud is:”Take DT, subset rows by i, then compute j grouped by by.\"\r\nExample\r\n\r\n\r\n# More data.table usage ideas at http://rstudio-pubs-static.s3.amazonaws.com/428441_39cf3780625b46aca650f50125b57506.html\r\n\r\n# Loading iris dataset as a data.table\r\niris.dt <- data.table::data.table(iris)\r\n\r\n# Summarising by species\r\n# .() syntax calls on specific columns rather than spelling out iris.dt$Sepal.Length\r\n\r\niris.mean <- iris.dt[, .(Mean_Sepal_Length = mean(Sepal.Length)), by=.(Species)]\r\niris.mean\r\n\r\n\r\n      Species Mean_Sepal_Length\r\n1:     setosa             5.006\r\n2: versicolor             5.936\r\n3:  virginica             6.588\r\n\r\n# Count observations by a grouping\r\niris.nrow <- iris.dt[, .N, by=.(Species)]\r\niris.nrow\r\n\r\n\r\n      Species  N\r\n1:     setosa 50\r\n2: versicolor 50\r\n3:  virginica 50\r\n\r\nThere are many other powerful options for data.table functions like .() and .N that can be used to VERY quickly get information from a data frame. Someday I’ll explore this package in more detail.\r\nFrom the help:\r\nA data.table is a list of vectors, just like a data.frame. However :\r\n\r\n  1. it never has or uses rownames. Rownames based indexing can be done by setting a key of one or more columns or done ad-hoc using the on argument (now preferred).\r\n\r\n  2. it has enhanced functionality in [.data.table for fast joins of keyed tables, fast aggregation, fast last observation carried forward (LOCF) and fast add/modify/delete of columns by reference with no copy at all.\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-01-27T10:36:12-08:00",
    "input_file": "day-4-datatable.utf8.md"
  },
  {
    "path": "posts/2021-01-26-day-3-plyr/",
    "title": "Day 3 - plyr::ddply()",
    "description": "The 3rd most used R package is... plyr",
    "author": [],
    "date": "2021-01-24",
    "categories": [],
    "contents": "\r\nplyr!\r\nplyr is not a package I’ve had to use frequently – likely because I use other tidyverse packages. dplyr was meant to be faster and more efficient than plyr. Perhaps plyr still has some uses. Here are the top 10 plyr functions:\r\n\r\n\r\nTopRFunc.plyr <- read.csv(\"https://github.com/v-kozhevnikov/GitHub_R_commands/raw/master/data/top_2000_functions.csv\") %>%\r\n  filter(library == 'plyr')\r\n\r\nknitr::kable(TopRFunc.plyr[1:10,2:3],\r\n             table.attr = \"style='width:60%;'\",\r\n             col.names = Hmisc::capitalize(names(TopRFunc.plyr[,2:3])),\r\n             caption = \"Top 10 plyr Functions on GitHub\") %>%\r\n  kableExtra::kable_styling(position = \"center\",\r\n                            bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))\r\n\r\n\r\n\r\nTable 1: Top 10 plyr Functions on GitHub\r\n\r\n\r\nContent\r\n\r\n\r\nCount\r\n\r\n\r\nddply\r\n\r\n\r\n9920\r\n\r\n\r\narrange\r\n\r\n\r\n3070\r\n\r\n\r\nmutate\r\n\r\n\r\n2789\r\n\r\n\r\nldply\r\n\r\n\r\n2647\r\n\r\n\r\ncount\r\n\r\n\r\n2277\r\n\r\n\r\ndlply\r\n\r\n\r\n2175\r\n\r\n\r\nsummarise\r\n\r\n\r\n1573\r\n\r\n\r\nrename\r\n\r\n\r\n1504\r\n\r\n\r\nl_ply\r\n\r\n\r\n1419\r\n\r\n\r\njoin\r\n\r\n\r\n1342\r\n\r\n\r\n\r\nplyr::ddply\r\n\\(#1\\) on our function list, plyr’s ddply. ddply takes a tedious task and makes it fit in one line: Split a Data Frame, Apply a Function, And Return Results In A Data Frame. \r\nExample with Iris Data\r\n\r\n\r\n# Borrowed from https://stackoverflow.com/questions/54774280/plyrddply-equivalent-in-dplyr\r\n# A function\r\nfunc = function(x) {\r\n  mod = lm(Sepal.Length ~ Petal.Width, data = x)\r\n  mod_coefs = broom::tidy(mod)\r\n}\r\n\r\n# plyr::ddply used with predefined function\r\nplyr.df <- plyr::ddply(iris, \"Species\", func)\r\nplyr.df\r\n\r\n\r\n     Species        term  estimate std.error statistic      p.value\r\n1     setosa (Intercept) 4.7771775 0.1239124 38.552856 8.983969e-38\r\n2     setosa Petal.Width 0.9301727 0.4637306  2.005847 5.052644e-02\r\n3 versicolor (Intercept) 4.0446404 0.4229151  9.563717 1.068715e-12\r\n4 versicolor Petal.Width 1.4263647 0.3155204  4.520673 4.035422e-05\r\n5  virginica (Intercept) 5.2694172 0.6555634  8.037998 1.929551e-10\r\n6  virginica Petal.Width 0.6508306 0.3207003  2.029405 4.798149e-02\r\n\r\n\r\nI am more familiar with dplyr methods that would look like this:\r\n\r\n\r\n# dplyr function chain style\r\ndplyr.df <- iris %>%\r\n  group_by(Species) %>%\r\n  do(func(.)) # uses grouped iris above as input\r\ndplyr.df\r\n\r\n\r\n# A tibble: 6 x 6\r\n# Groups:   Species [3]\r\n  Species    term        estimate std.error statistic  p.value\r\n  <fct>      <chr>          <dbl>     <dbl>     <dbl>    <dbl>\r\n1 setosa     (Intercept)    4.78      0.124     38.6  8.98e-38\r\n2 setosa     Petal.Width    0.930     0.464      2.01 5.05e- 2\r\n3 versicolor (Intercept)    4.04      0.423      9.56 1.07e-12\r\n4 versicolor Petal.Width    1.43      0.316      4.52 4.04e- 5\r\n5 virginica  (Intercept)    5.27      0.656      8.04 1.93e-10\r\n6 virginica  Petal.Width    0.651     0.321      2.03 4.80e- 2\r\n\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-01-27T10:36:40-08:00",
    "input_file": "day-3-plyr.utf8.md"
  },
  {
    "path": "posts/2021-01-26-day-2-dplyr/",
    "title": "Day 2 - dplyr::recode()",
    "description": "The 2nd most used R package is... dplyr",
    "author": [],
    "date": "2021-01-23",
    "categories": [],
    "contents": "\r\ndplyr! (Surprise #2?)\r\ndplyr has become a mainstay in my code: it’s easy to read, easy to write, and part of tidyverse – a collection of packages I use nearly every time I use R. Have you used all of the top 20 dplyr functions? Many of them are now deprecated since it was integrated with tidyverse.\r\n\r\n\r\nTopRFunc.dplyr <- read.csv(\"https://github.com/v-kozhevnikov/GitHub_R_commands/raw/master/data/top_2000_functions.csv\") %>%\r\n  filter(library == 'dplyr')\r\n\r\nknitr::kable(TopRFunc.dplyr[1:20,2:3],\r\n             table.attr = \"style='width:60%;'\",\r\n             col.names = Hmisc::capitalize(names(TopRFunc.dplyr[,2:3])),\r\n             caption = \"Top 20 dplyr Functions on GitHub\") %>%\r\n  kableExtra::kable_styling(position = \"center\",\r\n                            bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))\r\n\r\n\r\n\r\nTable 1: Top 20 dplyr Functions on GitHub\r\n\r\n\r\nContent\r\n\r\n\r\nCount\r\n\r\n\r\nfilter\r\n\r\n\r\n26507\r\n\r\n\r\nmutate\r\n\r\n\r\n20039\r\n\r\n\r\nselect\r\n\r\n\r\n15773\r\n\r\n\r\ngroup_by\r\n\r\n\r\n13959\r\n\r\n\r\nsummarise\r\n\r\n\r\n8227\r\n\r\n\r\narrange\r\n\r\n\r\n5694\r\n\r\n\r\nn\r\n\r\n\r\n4470\r\n\r\n\r\nleft_join\r\n\r\n\r\n4359\r\n\r\n\r\nsummarize\r\n\r\n\r\n3156\r\n\r\n\r\nrename\r\n\r\n\r\n2685\r\n\r\n\r\nungroup\r\n\r\n\r\n2478\r\n\r\n\r\nbind_rows\r\n\r\n\r\n2113\r\n\r\n\r\ndesc\r\n\r\n\r\n1928\r\n\r\n\r\ninner_join\r\n\r\n\r\n1719\r\n\r\n\r\ndistinct\r\n\r\n\r\n1317\r\n\r\n\r\ntbl_df\r\n\r\n\r\n1260\r\n\r\n\r\ncount\r\n\r\n\r\n1248\r\n\r\n\r\nstarts_with\r\n\r\n\r\n1134\r\n\r\n\r\nfuns\r\n\r\n\r\n991\r\n\r\n\r\nintersect\r\n\r\n\r\n959\r\n\r\n\r\ndplyr::recode\r\nComing in at #23 on our list, dplyr’s recode is a great help for me when working with GIS tables that come in coded values (i.e. land cover classifications). [recode()](https://dplyr.tidyverse.org/reference/recode.html) will take inputs and replace them with your new terms. This can be combined with other functions using pipes or grep() to match string patterns within the recode().\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-01-26T12:27:09-08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-01-26-day-1-ggplot2/",
    "title": "Day 1 - ggplot2::qplot()",
    "description": "The most used R package is... ggplot! Surprise?",
    "author": [],
    "date": "2021-01-22",
    "categories": [],
    "contents": "\r\nEmily Nebergall started this challenge for our Data Science Discord group. The goal is to learn a new R function every day and share what we have learned! R is a big code universe. I started today by perusing a “big data” analysis of the top 100 R packages used on all of GitHub. Each day, I will move down the list and pick a function I am unfamiliar with from the most popular R packages. I’ve used ggplot2 pretty extensively so finding something unfamiliar to me was challenging. Let’s see what the top 10 or 20 ggplot functions are: \r\n\r\n\r\nTopRFunc.ggplot <- read.csv(\"https://github.com/v-kozhevnikov/GitHub_R_commands/raw/master/data/top_2000_functions.csv\") %>%\r\n  filter(library == 'ggplot2')\r\n\r\nknitr::kable(TopRFunc.ggplot[1:20,2:3],\r\n             table.attr = \"style='width:60%;'\",\r\n             col.names = Hmisc::capitalize(names(TopRFunc.ggplot[,2:3])),\r\n             caption = \"Top 20 ggplot2 Functions on GitHub\") %>%\r\n  kableExtra::kable_styling(position = \"center\",\r\n                            bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"))\r\n\r\n\r\n\r\nTable 1: Top 20 ggplot2 Functions on GitHub\r\n\r\n\r\nContent\r\n\r\n\r\nCount\r\n\r\n\r\naes\r\n\r\n\r\n212161\r\n\r\n\r\nggplot\r\n\r\n\r\n129457\r\n\r\n\r\ntheme\r\n\r\n\r\n124240\r\n\r\n\r\nelement_text\r\n\r\n\r\n111714\r\n\r\n\r\ngeom_point\r\n\r\n\r\n58377\r\n\r\n\r\nelement_blank\r\n\r\n\r\n53501\r\n\r\n\r\nlabs\r\n\r\n\r\n52550\r\n\r\n\r\nggsave\r\n\r\n\r\n36011\r\n\r\n\r\ntheme_bw\r\n\r\n\r\n34839\r\n\r\n\r\ngeom_bar\r\n\r\n\r\n31209\r\n\r\n\r\nelement_line\r\n\r\n\r\n29698\r\n\r\n\r\nylab\r\n\r\n\r\n28066\r\n\r\n\r\nfacet_grid\r\n\r\n\r\n26900\r\n\r\n\r\ngeom_line\r\n\r\n\r\n23983\r\n\r\n\r\nxlab\r\n\r\n\r\n22596\r\n\r\n\r\nfacet_wrap\r\n\r\n\r\n20047\r\n\r\n\r\ncoord_flip\r\n\r\n\r\n19598\r\n\r\n\r\nscale_y_continuous\r\n\r\n\r\n19598\r\n\r\n\r\ngeom_boxplot\r\n\r\n\r\n18735\r\n\r\n\r\ntheme_classic\r\n\r\n\r\n15830\r\n\r\n\r\n\r\nggplot2::qplot\r\nNo surprise still with the top 10 or even 20 ggplot functions. I had to scroll down to #45 (not bad!) before finding one I haven’t heard of: quick plot!\r\nqplot is meant to be a shortcut for plotting data. It lacks the fine control ggplot has but it works great for quickly visualizing simple data sets. \r\nExample\r\n\r\n\r\nqplot(body_mass_g, flipper_length_mm, data = palmerpenguins::penguins, color = species)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-01-26-day-1-ggplot2/day-1-ggplot2_files/figure-html5/unnamed-chunk-2-1.png",
    "last_modified": "2021-01-26T12:27:01-08:00",
    "input_file": {}
  }
]
